{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "14286eb9",
   "metadata": {},
   "source": [
    "# Bayesian Sparse Feature Selection on an Unknown Dataset\n",
    "\n",
    "This notebook demonstrates how to apply the Bayesian Sparse Feature Selector to an arbitrary dataset with unknown ground truth. It mirrors the workflow of demo.ipynb, but assumes no knowledge of the true supports. Feature names are anonymized during analysis and mapped back for interpretability.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58470f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install -e .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c1c868d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, Markdown\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from plotly import io as pio\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import gemss.config as C\n",
    "from gemss.feature_selection.inference import BayesianFeatureSelector\n",
    "from gemss.diagnostics.visualizations import show_label_histogram, show_final_alphas\n",
    "from gemss.diagnostics.outliers import show_outlier_features_by_component\n",
    "from gemss.diagnostics.result_postprocessing import (\n",
    "    recover_solutions,\n",
    "    show_algorithm_progress,\n",
    "    show_unique_features,\n",
    "    show_features_in_solutions,\n",
    ")\n",
    "from gemss.diagnostics.simple_regressions import show_regression_results_for_solutions\n",
    "from gemss.diagnostics.performance_tests import run_performance_diagnostics\n",
    "from gemss.diagnostics.recommendations import display_recommendations\n",
    "from gemss.utils import show_solution_summary\n",
    "\n",
    "pio.renderers.default = \"notebook_connected\"  # Ensures plotly plots show in notebooks\n",
    "\n",
    "from gemss.data_handling.data_processing import (\n",
    "    load_data,\n",
    "    preprocess_features,\n",
    "    get_feature_name_mapping,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8879eb36",
   "metadata": {},
   "source": [
    "# Your setup\n",
    "\n",
    "In this section, define the specifics for your data and parameters for the feature selection algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fddf904",
   "metadata": {},
   "source": [
    "## Govern verbosity and outputting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "377a3ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show plots of algorithm progress over iterations\n",
    "show_search_history = True\n",
    "\n",
    "# Detect outlier features (in each component) by statistical means\n",
    "# Ideally, outliers == solutions\n",
    "outlier_analysis = True\n",
    "\n",
    "# Choose overall verbosity for various outputs\n",
    "verbose = True\n",
    "\n",
    "# Whether to run regressions for the selected solutions and show results\n",
    "run_regressions_for_solutions = True\n",
    "\n",
    "# Whether to run performance diagnostics\n",
    "# The diagnostics is necessary for showing recommendations\n",
    "# but can be run quietly, if desired\n",
    "run_diagnostics = True\n",
    "verbose_diagnostics = True\n",
    "\n",
    "# Whether to show recommendations based on diagnostics\n",
    "# requires `run_diagnostics = True` too\n",
    "show_recommendations = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71df62a6",
   "metadata": {},
   "source": [
    "## Set parameters to handle your dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8233ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset parameters\n",
    "# the CSV file should be in the ../data/ directory\n",
    "# the index and label column names must be included in the dataset\n",
    "csv_dataset_name = \"shelflife_data_all_preprocessed.csv\"\n",
    "index_column_name = \"sample ID\"\n",
    "label_column_name = \"label\"\n",
    "\n",
    "# NA handling options\n",
    "# Options are:\n",
    "# - \"response\": drop rows with NA in the response column only (default).\n",
    "# - \"all\": drop rows with NA in any column.\n",
    "# - \"none\": do not drop any rows.\n",
    "dropna_columns = \"response\"\n",
    "\n",
    "# Apply standard scaling to features\n",
    "apply_standard_scaling = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48aae0a7",
   "metadata": {},
   "source": [
    "### Load your data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24e6c278",
   "metadata": {},
   "outputs": [],
   "source": [
    "if verbose:\n",
    "    display(Markdown(\"#### Loading your data\"))\n",
    "\n",
    "df, response = load_data(\n",
    "    csv_dataset_name,\n",
    "    index_column_name,\n",
    "    label_column_name,\n",
    ")\n",
    "X, y = preprocess_features(\n",
    "    df,\n",
    "    response,\n",
    "    dropna=dropna_columns,\n",
    "    apply_standard_scaling=apply_standard_scaling,\n",
    "    verbose=verbose,\n",
    ")\n",
    "feature_to_name = get_feature_name_mapping(df)\n",
    "\n",
    "if verbose:\n",
    "    display(Markdown(\"Your data:\"))\n",
    "    display(Markdown(f\"- Number of labels: **{len(np.unique(y))}**\"))\n",
    "    display(Markdown(f\"- Number of samples: **{X.shape[0]}**\"))\n",
    "    display(Markdown(f\"- Number of features: **{X.shape[1]}**\"))\n",
    "    display(Markdown(f\"{list(feature_to_name.values())}\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34d0b861",
   "metadata": {},
   "source": [
    "## Set parameters for the feature selection algorithm\n",
    "\n",
    "- First, default contant values are loaded by the config module.\n",
    "- Then override the settings of select parameters as needed.\n",
    "\n",
    "- The algorithm usually takes about 1+ minute per 1000 training iterations on CPU for the default 'sss' prior. The 'student' prior is faster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf9590dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO NOT CHANGE THIS CELL unless you know what you're doing\n",
    "\n",
    "# First load the default constants defined by the config module (including nonsensical values for your data)\n",
    "constants = C.as_dict()\n",
    "\n",
    "# Override the settings for this specific dataset\n",
    "constants[\"N_SAMPLES\"] = df.shape[0]\n",
    "constants[\"N_FEATURES\"] = df.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d66e3ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SET YOUR PARAMETERS HERE\n",
    "\n",
    "# Algorithm settings\n",
    "constants[\"PRIOR_TYPE\"] = \"sss\"\n",
    "\n",
    "### PRIOR_SPARSITY = number of supporting dimensions for the 'sss' prior\n",
    "### used only with the 'sss' prior\n",
    "constants[\"PRIOR_SPARSITY\"] = constants[\"DESIRED_SPARSITY\"]\n",
    "\n",
    "### VAR_SPIKE and VAR_SLAB are only used with 'ss' and 'sss' prior\n",
    "### ...VAR_SPIKE: parameter with the most influence on solution quality\n",
    "### ...smaller VAR_SPIKE => more sparsity, i.e. fewer nonzero solutions\n",
    "### ...increse VAR_SPIKE when all features converge to 0, typically in a uniform manner\n",
    "### ...decrease VAR_SPIKE when there are too many nonzero features at the end of the run\n",
    "constants[\"VAR_SPIKE\"] = 0.0005\n",
    "## Prior hyperparameters\n",
    "constants[\"VAR_SLAB\"] = 100.0\n",
    "\n",
    "### WEIGHT_SLAB and WEIGHT_SPIKE are only used with 'ss' prior\n",
    "constants[\"WEIGHT_SLAB\"] = 0.9  # not used with 'sss' prior\n",
    "constants[\"WEIGHT_SPIKE\"] = 0.1  # not used with 'sss' prior\n",
    "constants[\"STUDENT_DF\"] = 1\n",
    "constants[\"STUDENT_SCALE\"] = 1.0\n",
    "\n",
    "## SGD optimization settings\n",
    "### N_ITER = number of training iterations (runtime approximately 1+ minutes/1000 iterations)\n",
    "### increase/decrease depending on both the ELBO and the mus' convergence behavior\n",
    "constants[\"N_ITER\"] = 3000\n",
    "\n",
    "## Regularization settings to make solutions more distinct\n",
    "### IS_REGULARIZED = whether to use penalization based on average Jaccard similarity among solutions\n",
    "### ...preferrably False or True with small LAMBDA_JACCARD at this moment\n",
    "constants[\"IS_REGULARIZED\"] = False\n",
    "### LAMBDA_JACCARD: larger values => more differentiated feature sets\n",
    "### ...it is safer to use smaller values and increase only if needed\n",
    "### ...if the ELBO converges to a too large value (in absolute terms), your lambda is probably too large\n",
    "constants[\"LAMBDA_JACCARD\"] = 500.0\n",
    "\n",
    "# Properties of the desired solutions\n",
    "# N_CANDIDATE_SOLUTIONS = number of candidate solutions\n",
    "#                       = no. components of Gaussian mixture that approximate the posterior\n",
    "constants[\"N_CANDIDATE_SOLUTIONS\"] = 8\n",
    "constants[\"DESIRED_SPARSITY\"] = 5  # Expected # of features per solution\n",
    "constants[\"MIN_MU_THRESHOLD\"] = 0.25  # minimum |Î¼| to consider a feature nonzero"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75c01117",
   "metadata": {},
   "source": [
    "# Run the feature selector on your data\n",
    "\n",
    "There is no need to touch any code below this cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34906baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "selector = BayesianFeatureSelector(\n",
    "    n_features=constants[\"N_FEATURES\"],\n",
    "    n_components=constants[\"N_CANDIDATE_SOLUTIONS\"],\n",
    "    X=X,\n",
    "    y=y,\n",
    "    prior=constants[\"PRIOR_TYPE\"],\n",
    "    sss_sparsity=constants[\"PRIOR_SPARSITY\"],\n",
    "    var_slab=constants[\"VAR_SLAB\"],\n",
    "    var_spike=constants[\"VAR_SPIKE\"],\n",
    "    weight_slab=constants[\"WEIGHT_SLAB\"],\n",
    "    weight_spike=constants[\"WEIGHT_SPIKE\"],\n",
    "    student_df=constants[\"STUDENT_DF\"],\n",
    "    student_scale=constants[\"STUDENT_SCALE\"],\n",
    "    lr=constants[\"LEARNING_RATE\"],\n",
    "    batch_size=constants[\"BATCH_SIZE\"],\n",
    "    n_iter=constants[\"N_ITER\"],\n",
    ")\n",
    "\n",
    "history = selector.optimize(\n",
    "    regularize=constants[\"IS_REGULARIZED\"],\n",
    "    lambda_jaccard=constants[\"LAMBDA_JACCARD\"],\n",
    "    verbose=verbose,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c9c908a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if show_search_history:\n",
    "    show_algorithm_progress(\n",
    "        history,\n",
    "        original_feature_names_mapping=feature_to_name,\n",
    "    )\n",
    "\n",
    "    show_final_alphas(\n",
    "        history,\n",
    "        show_bar_plot=False,\n",
    "        show_pie_chart=True,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21569d44",
   "metadata": {},
   "source": [
    "## Outlier Analysis\n",
    "\n",
    "The outlier analysis helps identify features with unusually high or low importance values in each component.\n",
    "\n",
    "Ideally, the detected outliers are identical to the final solutions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afff7858",
   "metadata": {},
   "outputs": [],
   "source": [
    "if outlier_analysis:\n",
    "    for outlier_threshold_coeff in [2.5, 3.0, 3.5]:\n",
    "        show_outlier_features_by_component(\n",
    "            history=history,\n",
    "            use_median=False,\n",
    "            outlier_threshold_coeff=outlier_threshold_coeff,\n",
    "            use_markdown=True,\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "875e216f",
   "metadata": {},
   "source": [
    "# Show the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6fca799",
   "metadata": {},
   "outputs": [],
   "source": [
    "solutions, final_parameters, full_nonzero_solutions = recover_solutions(\n",
    "    search_history=history,\n",
    "    desired_sparsity=constants[\"DESIRED_SPARSITY\"],\n",
    "    min_mu_threshold=constants[\"MIN_MU_THRESHOLD\"],\n",
    "    verbose=verbose,\n",
    "    original_feature_names_mapping=feature_to_name,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3067318f",
   "metadata": {},
   "source": [
    "## Overview of full (long) solutions\n",
    "\n",
    "The 'long' solutions are the actual solutions (full sets of features) found by the algorithm. Their sparsity may not be as strong as desired."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8102165a",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_solution_summary(\n",
    "    solution_data=full_nonzero_solutions,\n",
    "    title=\"Full solutions found by the feature selector, ordered by importance\",\n",
    "    value_column=\"Feature\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12a41660",
   "metadata": {},
   "source": [
    "## Final (short) candidate solutions\n",
    "\n",
    "The long solutions are further shortened to the required number of features based on the final mu values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "066152e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_features_in_solutions(\n",
    "    solutions=solutions,\n",
    "    history=history,\n",
    "    constants=constants,\n",
    "    use_markdown=True,\n",
    ")\n",
    "\n",
    "show_unique_features(\n",
    "    solutions=solutions,\n",
    "    use_markdown=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2a9fa97",
   "metadata": {},
   "outputs": [],
   "source": [
    "if run_regressions_for_solutions:\n",
    "    show_regression_results_for_solutions(\n",
    "        solutions,\n",
    "        df=df,\n",
    "        y=y,\n",
    "        penalty=\"l1\",\n",
    "        verbose=True,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c168e1e",
   "metadata": {},
   "source": [
    "# Performance diagnostics and recommendations\n",
    "\n",
    "Let us assess the feature selector's progress history to evaluate the reliability of the results. Based on the diagnostics, hyperparameter tuning might be recommended."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2fc5d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "if run_performance_diagnostics:\n",
    "    diagnostics = run_performance_diagnostics(\n",
    "        history,\n",
    "        desired_sparsity=constants[\"DESIRED_SPARSITY\"],\n",
    "        verbose=verbose_diagnostics,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d13cc7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if run_performance_diagnostics and show_recommendations:\n",
    "    display_recommendations(diagnostics=diagnostics, constants=constants)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
