{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "14286eb9",
   "metadata": {},
   "source": [
    "# Bayesian Sparse Feature Selection on an Unknown Dataset\n",
    "\n",
    "This notebook demonstrates how to apply the Bayesian Sparse Feature Selector to an arbitrary dataset with unknown ground truth. It mirrors the workflow of demo.ipynb, but assumes no knowledge of the true supports. Feature names are anonymized during analysis and mapped back for interpretability.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58470f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install -e .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1c868d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, Markdown\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from plotly import io as pio\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import gemss.config as C\n",
    "from gemss.feature_selection.inference import BayesianFeatureSelector\n",
    "from gemss.diagnostics.visualizations import show_label_histogram, show_final_alphas\n",
    "from gemss.diagnostics.result_postprocessing import (\n",
    "    recover_solutions,\n",
    "    show_algorithm_progress,\n",
    "    get_long_solutions_df,\n",
    "    show_regression_results_for_solutions,\n",
    ")\n",
    "from gemss.diagnostics.performance_tests import run_performance_diagnostics\n",
    "from gemss.diagnostics.recommendations import display_recommendations\n",
    "\n",
    "pio.renderers.default = \"notebook_connected\"  # Ensures plotly plots show in notebooks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8879eb36",
   "metadata": {},
   "source": [
    "# Set parameters\n",
    "\n",
    "- The algorithm usually takes about 1+ minute per 1000 training iterations on CPU for the default 'sss' prior. The 'student' prior is faster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8233ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset parameters\n",
    "# the CSV file should be in the ../data/ directory\n",
    "# the index and label column names must be included in the dataset\n",
    "csv_dataset_name = \"shelflife_data_all_preprocessed.csv\"\n",
    "index_column_name = \"sample ID\"\n",
    "label_column_name = \"label\"\n",
    "\n",
    "# Apply standard scaling to features\n",
    "apply_scaling = False\n",
    "\n",
    "# Show plots of algorithm progress over iterations\n",
    "show_search_history = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24e6c278",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set parameters\n",
    "constants = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9089897e",
   "metadata": {},
   "source": [
    "# Load and preprocess the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f349acd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(f\"../data/{csv_dataset_name}\", index_col=index_column_name)\n",
    "y = df.pop(label_column_name).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d66e3ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "constants = C.as_dict()\n",
    "\n",
    "# Override the settings for this specific dataset\n",
    "constants[\"N_SAMPLES\"] = df.shape[0]\n",
    "constants[\"N_FEATURES\"] = df.shape[1]\n",
    "constants[\"N_GENERATING_SOLUTIONS\"] = np.inf\n",
    "\n",
    "# Algorithm settings\n",
    "constants[\"PRIOR_TYPE\"] = \"sss\"  # 'sss', 'spike-and-slab', or 'student'\n",
    "constants[\"PRIOR_SPARSITY\"] = constants[\"DESIRED_SPARSITY\"]\n",
    "constants[\"VAR_SLAB\"] = 100.0\n",
    "constants[\"VAR_SPIKE\"] = 0.001\n",
    "constants[\"WEIGHT_SLAB\"] = 0.9  # not used with 'sss' prior\n",
    "constants[\"WEIGHT_SPIKE\"] = 0.1  # not used with 'sss' prior\n",
    "constants[\"STUDENT_DF\"] = 1  # not used with 'sss' prior\n",
    "constants[\"STUDENT_SCALE\"] = 1.0  # not used with 'sss' prior\n",
    "constants[\"LEARNING_RATE\"] = 0.002\n",
    "constants[\"BATCH_SIZE\"] = 16\n",
    "constants[\"N_ITER\"] = 3000  # number of training iterations.\n",
    "constants[\"IS_REGULARIZED\"] = True\n",
    "constants[\"LAMBDA_JACCARD\"] = 500.0\n",
    "\n",
    "# Solution settings\n",
    "constants[\"N_CANDIDATE_SOLUTIONS\"] = (\n",
    "    8  # Number of mixture components (candidate solutions)\n",
    ")\n",
    "constants[\"DESIRED_SPARSITY\"] = 6  # Expected # of features per solution\n",
    "constants[\"MIN_MU_THRESHOLD\"] = 0.25  # minimum |Î¼| to consider a feature nonzero"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9426a56b",
   "metadata": {},
   "source": [
    "### Rename features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f30a26d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define feature renaming dictionaries\n",
    "original_feature_names = list(df.columns)\n",
    "\n",
    "name_to_feature = {\n",
    "    orig: f\"feature_{i}\" for i, orig in enumerate(original_feature_names)\n",
    "}\n",
    "feature_to_name = {v: k for k, v in name_to_feature.items()}\n",
    "\n",
    "df = df.rename(columns=name_to_feature)\n",
    "# display(Markdown(\"**Feature renaming dictionary:**\"))\n",
    "# display(Markdown(f\"```{name_to_feature}```\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab651594",
   "metadata": {},
   "source": [
    "### Optional: apply standard scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9a151d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "if apply_scaling:\n",
    "    scaler = StandardScaler()\n",
    "    X = scaler.fit_transform(df.values)\n",
    "    display(Markdown(\"Applied standard scaling to features.\"))\n",
    "else:\n",
    "    X = df.values\n",
    "    display(Markdown(\"No scaling applied to features.\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75c01117",
   "metadata": {},
   "source": [
    "# Run the feature selector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34906baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "selector = BayesianFeatureSelector(\n",
    "    n_features=constants[\"N_FEATURES\"],\n",
    "    n_components=constants[\"N_CANDIDATE_SOLUTIONS\"],\n",
    "    X=X,\n",
    "    y=y,\n",
    "    prior=constants[\"PRIOR_TYPE\"],\n",
    "    sss_sparsity=constants[\"PRIOR_SPARSITY\"],\n",
    "    var_slab=constants[\"VAR_SLAB\"],\n",
    "    var_spike=constants[\"VAR_SPIKE\"],\n",
    "    weight_slab=constants[\"WEIGHT_SLAB\"],\n",
    "    weight_spike=constants[\"WEIGHT_SPIKE\"],\n",
    "    student_df=constants[\"STUDENT_DF\"],\n",
    "    student_scale=constants[\"STUDENT_SCALE\"],\n",
    "    lr=constants[\"LEARNING_RATE\"],\n",
    "    batch_size=constants[\"BATCH_SIZE\"],\n",
    "    n_iter=constants[\"N_ITER\"],\n",
    ")\n",
    "\n",
    "history = selector.optimize(\n",
    "    regularize=constants[\"IS_REGULARIZED\"],\n",
    "    lambda_jaccard=constants[\"LAMBDA_JACCARD\"],\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "if show_search_history:\n",
    "    show_algorithm_progress(\n",
    "        history,\n",
    "        original_feature_names_mapping=feature_to_name,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "875e216f",
   "metadata": {},
   "source": [
    "# Show the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6fca799",
   "metadata": {},
   "outputs": [],
   "source": [
    "solutions, final_parameters, full_nonzero_solutions = recover_solutions(\n",
    "    search_history=history,\n",
    "    desired_sparsity=constants[\"DESIRED_SPARSITY\"],\n",
    "    min_mu_threshold=constants[\"MIN_MU_THRESHOLD\"],\n",
    "    verbose=True,\n",
    "    original_feature_names_mapping=feature_to_name,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3067318f",
   "metadata": {},
   "source": [
    "### Overview of full solutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05b5c9ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_final_alphas(\n",
    "    history,\n",
    "    show_bar_plot=False,\n",
    "    show_pie_chart=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8102165a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full_solutions = get_long_solutions_df(full_nonzero_solutions)\n",
    "display(df_full_solutions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12a41660",
   "metadata": {},
   "source": [
    "# Final Selected Solutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "066152e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Markdown(f\"**Required sparsity** = {constants['DESIRED_SPARSITY']}\"))\n",
    "for component, features in solutions.items():\n",
    "    i = component.split(\"_\")[-1]\n",
    "    alpha = history[\"alpha\"][-1][int(i)]\n",
    "    display(Markdown(f\"## Candidate solution no. {i}:\"))\n",
    "    display(Markdown(f\"**Component weight** = {alpha:.3f}\"))\n",
    "    for feature in features:\n",
    "        display(Markdown(f\"- {feature}\"))\n",
    "\n",
    "\n",
    "# Print unique features\n",
    "unique_features = set()\n",
    "\n",
    "for _, features in solutions.items():\n",
    "    unique_features.update(features)\n",
    "\n",
    "display(\n",
    "    Markdown(\n",
    "        f\"## Unique features across all {len(solutions)} solutions: {len(unique_features)} total\"\n",
    "    )\n",
    ")\n",
    "display(Markdown(f\"```{sorted(unique_features)}```\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2a9fa97",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.rename(columns=feature_to_name)\n",
    "\n",
    "show_regression_results_for_solutions(\n",
    "    solutions,\n",
    "    df=df,\n",
    "    y=y,\n",
    "    penalty=\"l1\",\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c168e1e",
   "metadata": {},
   "source": [
    "# Feature selector's performance tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2fc5d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "diagnostics = run_performance_diagnostics(\n",
    "    history,\n",
    "    desired_sparsity=constants[\"DESIRED_SPARSITY\"],\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d13cc7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_recommendations(\n",
    "    diagnostics=diagnostics,\n",
    "    constants=constants,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
