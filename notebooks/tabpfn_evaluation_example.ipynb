{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TabPFN Evaluation with SHAP Explanations\n",
    "\n",
    "This notebook demonstrates the usage of the `tabpfn_evaluate` function for evaluating a dataset with TabPFN, outer cross-validation, and SHAP feature importances.\n",
    "\n",
    "This notebook uses a public dataset to show a minmal working example. Custom datasets with results from GEMSS feature selector should be processed using *tabpfn_evaluate_custom_dataset_results.ipynb*.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "from IPython.display import display, Markdown\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pyarrow.parquet as pq\n",
    "import plotly.express as px\n",
    "from plotly import io as pio\n",
    "import ast\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "from gemss.postprocessing.tabpfn_evaluation import tabpfn_evaluate\n",
    "\n",
    "# Example data\n",
    "from sklearn.datasets import load_iris, fetch_california_housing\n",
    "\n",
    "pio.renderers.default = \"notebook_connected\"  # Ensures plotly plots show in notebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose task: 'classification' or 'regression'\n",
    "task = \"regression\"\n",
    "\n",
    "# Load example datasets\n",
    "if task == \"classification\":\n",
    "    data = load_iris()\n",
    "    X, y = data.data, data.target\n",
    "    feature_names = data.feature_names\n",
    "else:\n",
    "    data = fetch_california_housing()\n",
    "    X, y = data.data, data.target\n",
    "    feature_names = data.feature_names\n",
    "\n",
    "# Shuffle for better cross-validation splits\n",
    "X, y = shuffle(X, y, random_state=42)\n",
    "\n",
    "# Subsample heavily for faster demo\n",
    "n_samples_allowed = 100\n",
    "if X.shape[0] > n_samples_allowed:\n",
    "    X = X[:n_samples_allowed]\n",
    "    y = y[:n_samples_allowed]\n",
    "n_features_allowed = 5\n",
    "if X.shape[1] > n_features_allowed:\n",
    "    X = X[:, :n_features_allowed]\n",
    "    feature_names = feature_names[:n_features_allowed]\n",
    "\n",
    "X_df = pd.DataFrame(X, columns=feature_names)\n",
    "X_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run TabPFN Evaluation with SHAP\n",
    "\n",
    "- Outer cross-validation\n",
    "- Feature scaling (standard, minmax or None)\n",
    "- SHAP explanations (parameter *'explain'*)\n",
    "- Prints metrics for each fold\n",
    "\n",
    "> For large X, SHAP explanations take time. For a quick demo, use a small subset or reduce folds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = tabpfn_evaluate(\n",
    "    X_df,\n",
    "    y,\n",
    "    apply_scaling=\"standard\",\n",
    "    outer_cv_folds=2,\n",
    "    tabpfn_kwargs=None,\n",
    "    random_state=42,\n",
    "    verbose=True,\n",
    "    explain=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CV Results: Average Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(results[\"average_scores\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Importances (SHAP, Mean Per Fold)\n",
    "Each dictionary below shows mean absolute SHAP values for features in a CV fold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for fold, shap_imp in enumerate(results.get(\"shap_explanations_per_fold\", [])):\n",
    "    display(Markdown(f\"Fold {fold+1} SHAP Feature Importances:\"))\n",
    "    display(pd.Series(shap_imp).sort_values(ascending=False))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61560b28",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
