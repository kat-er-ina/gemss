{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a60e71fc",
   "metadata": {},
   "source": [
    "# GEMSS Demo\n",
    "\n",
    "This notebook demonstrates the GEMSS algorithm on artificially generated data.\n",
    "\n",
    "> **Note:**\n",
    "Ensure that the `gemss` package and dependencies are installed.\n",
    "\n",
    "> **Configuration:**\n",
    "All parameters can be configured in json files in ```gemss/config```.\n",
    "\n",
    "**The artificial data:**\n",
    "- Are generated randomly with a random seed.\n",
    "- Have the prescribed dimensions (sample size, number of features), noise level, ratio of NaNs (evenly distributed), response type (continuous or binarized) and (for binary classification problems) prevalence of the minority class.\n",
    "- Have a predefined number of \"generating\" solutions, each of the same sparsity. The generating features are picked at random and have random weights.\n",
    "- The generated data can be saved (optional).\n",
    "\n",
    "**Using GEMSS:**\n",
    "- Define hyperparameters as instructed below and run the feature selector.\n",
    "- Assess the convergence. If needed, adjust hyperparameters and rerun.\n",
    "- Inspect the three types of solutions (\"outliers\", \"full\", \"top\"), their properties and modeling potential in simple linear/logistic models.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6845e612",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, Markdown\n",
    "import plotly.io as pio\n",
    "\n",
    "import gemss.config as C\n",
    "from gemss.config import display_current_config\n",
    "from gemss.data_handling.generate_artificial_dataset import (\n",
    "    generate_artificial_dataset,\n",
    ")\n",
    "from gemss.feature_selection.inference import BayesianFeatureSelector\n",
    "from gemss.utils.visualizations import (\n",
    "    show_correlation_matrix,\n",
    "    show_features_in_components,\n",
    ")\n",
    "from gemss.diagnostics.recommendations import display_parameter_adjustment_summary\n",
    "from gemss.postprocessing.result_postprocessing import (\n",
    "    get_features_from_solutions,\n",
    "    get_unique_features,\n",
    "    recover_solutions,\n",
    "    show_algorithm_progress,\n",
    "    show_solution_summary,\n",
    "    show_unique_features_from_full_solutions,\n",
    "    compare_true_and_found_features,\n",
    ")\n",
    "from gemss.utils.utils import show_solution_summary\n",
    "from gemss.postprocessing.simple_regressions import (\n",
    "    solve_any_regression,\n",
    "    show_regression_metrics,\n",
    ")\n",
    "from gemss.utils.visualizations import show_final_alphas\n",
    "\n",
    "pio.renderers.default = \"notebook_connected\"  # Ensures plotly plots show in notebooks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18fa2202",
   "metadata": {},
   "source": [
    "# Hyperparameter overview\n",
    "\n",
    "Review the default hyperparameter setting. It can be overridden as needed: see the JSON configuration files in ```gemss/config```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfc67dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_current_config(\n",
    "    constants=C.as_dict(),\n",
    "    constant_type=\"all\",\n",
    ")\n",
    "display_parameter_adjustment_summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d294cdd",
   "metadata": {},
   "source": [
    "# Generate artificial dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "104d75a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate dataset\n",
    "df, y, generating_solutions, parameters = generate_artificial_dataset(\n",
    "    n_samples=C.N_SAMPLES,\n",
    "    n_features=C.N_FEATURES,\n",
    "    n_solutions=C.N_GENERATING_SOLUTIONS,\n",
    "    sparsity=C.SPARSITY,\n",
    "    noise_data_std=C.NOISE_STD,\n",
    "    nan_ratio=C.NAN_RATIO,\n",
    "    binarize=C.BINARIZE,\n",
    "    binary_response_ratio=C.BINARY_RESPONSE_RATIO,\n",
    "    random_seed=C.DATASET_SEED,\n",
    "    save_to_csv=False,  # Set to True to save generated data\n",
    "    print_data_overview=True,\n",
    "    show_feature_correlations=False,\n",
    ")\n",
    "\n",
    "support_indices = parameters[\"support_indices\"].sum()\n",
    "true_support_features = [f\"feature_{i}\" for i in set(support_indices)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a945c681",
   "metadata": {},
   "source": [
    "# Classical approach: simple regressions\n",
    "\n",
    "If there is an acceptable amount of missing values, solve the problem using logistic/linear regression with regularization.\n",
    "\n",
    "We run l2- and l1-regularized regression on the KNOWN sets of features (*solution_0*, *solution_1*, ...) and on the whole original feature set (including all the noise) to see the \"baseline\" performance of such models.\n",
    "Observe the number of nonzero coefficients (*n_nonzero_coefficients*) for the model with the original feature set: even the optimal l1-regularized model ($\\lambda$ optimalized by inner CV) does not achieve perfect sparsity.\n",
    "Moreover, even some performance metrics of models that are provided with perfect feature sets do not reach the perfect scores 1.0. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ec94b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show regression results only for the generating solutions and the full feature set\n",
    "generating_solutions_expanded = generating_solutions\n",
    "generating_solutions_expanded[\"original feature set\"] = df.columns.to_list()\n",
    "\n",
    "for penalty in [\"l1\", \"l2\"]:\n",
    "    metrics = solve_any_regression(\n",
    "        solutions=generating_solutions_expanded,\n",
    "        df=df,\n",
    "        response=y,\n",
    "        apply_scaling=\"standard\",\n",
    "        penalty=penalty,\n",
    "        verbose=False,  # if true, shows detailed results for each solution\n",
    "    )\n",
    "    show_regression_metrics(\n",
    "        metrics_df=metrics,\n",
    "        title=f\"Results on training data (penalty={penalty})\",\n",
    "        use_markdown=True,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccf3a053",
   "metadata": {},
   "source": [
    "# GEMSS: running a Bayesian feature selector\n",
    "\n",
    "Find multiple solutions simultaneously. It is recommended to set *N_CANDIDATE_SOLUTIONS* 2-3x the number of expected \"true\" solutions because of the properties of solutions in linear vector spaces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0abe75e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "selector = BayesianFeatureSelector(\n",
    "    n_features=C.N_FEATURES,\n",
    "    n_components=C.N_CANDIDATE_SOLUTIONS,\n",
    "    X=df.values,\n",
    "    y=y,\n",
    "    prior=C.PRIOR_TYPE,\n",
    "    sss_sparsity=C.PRIOR_SPARSITY,\n",
    "    sample_more_priors_coeff=C.SAMPLE_MORE_PRIORS_COEFF,\n",
    "    var_slab=C.VAR_SLAB,\n",
    "    var_spike=C.VAR_SPIKE,\n",
    "    weight_slab=C.WEIGHT_SLAB,\n",
    "    weight_spike=C.WEIGHT_SPIKE,\n",
    "    student_df=C.STUDENT_DF,\n",
    "    student_scale=C.STUDENT_SCALE,\n",
    "    lr=C.LEARNING_RATE,\n",
    "    batch_size=C.BATCH_SIZE,\n",
    "    n_iter=C.N_ITER,\n",
    ")\n",
    "\n",
    "history = selector.optimize(\n",
    "    regularize=C.IS_REGULARIZED,\n",
    "    lambda_jaccard=C.LAMBDA_JACCARD,\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23c64df1",
   "metadata": {},
   "source": [
    "## Assess algorithm convergence\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73bfb0c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The most important function: show_algorithm_progress\n",
    "# visualizes the optimization process by displaying the evolution of key metrics over iterations\n",
    "# essential for understanding model behavior and spotting issues\n",
    "show_algorithm_progress(history, subsample_history_for_plotting=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e044c153",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare the relative weights of the candidate solutions\n",
    "show_final_alphas(\n",
    "    history,\n",
    "    show_bar_plot=False,\n",
    "    show_pie_chart=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aa123df",
   "metadata": {},
   "source": [
    "# Extract solutions from the components\n",
    "\n",
    "Analyze the feature selection process to extract solutions. There are 3 basic solution types (under ideal conditions, all should be equivalent):\n",
    "\n",
    "- **top** solutions recover strictly the predefined number of features with the greatest (absolute) $\\mu$ values.\n",
    "\n",
    "- **full** solutions recover all features, whose $\\mu$ values exceed a hard predefined $\\epsilon$ threshold. If there are fewer such features than the required sparsity, it backtracks those that \"zeroed-out\" as last.\n",
    "\n",
    "- **outlier** solutions use statistics to detect all features with STD (or MAD) greater than a given threshold. They are good for flexible solution recovery when sparsity is not known apriori. The downside might be a sizeable overlap of candidate solutions (if the STD is too small) or too few features found (if STD is too large) - this is mitigated by having multiple thresholds. Recommended STD values range from 2.0 to 4.0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5852ccb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_solutions, top_solutions, outlier_solutions, final_parameters = recover_solutions(\n",
    "    search_history=history,\n",
    "    desired_sparsity=C.DESIRED_SPARSITY,\n",
    "    min_mu_threshold=C.MIN_MU_THRESHOLD,\n",
    "    use_median_for_outlier_detection=C.USE_MEDIAN_FOR_OUTLIER_DETECTION,\n",
    "    outlier_deviation_thresholds=C.OUTLIER_DEVIATION_THRESHOLDS,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "904a22b0",
   "metadata": {},
   "source": [
    "## Solutions by outlier detection\n",
    "\n",
    "The outlier analysis helps identify features with unusually high importance values (mu, either positive or negative) in each component."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be85724a",
   "metadata": {},
   "outputs": [],
   "source": [
    "outlier_features = {}\n",
    "for deviation, df_outlier in outlier_solutions.items():\n",
    "    outlier_features[f\"{deviation}\"] = get_features_from_solutions(df_outlier)\n",
    "    features_found = get_unique_features(outlier_features[f\"{deviation}\"])\n",
    "\n",
    "    show_solution_summary(\n",
    "        solution_data=df_outlier,\n",
    "        title=f\"Outlier solutions ({deviation})\",\n",
    "        value_column=\"Feature\",\n",
    "    )\n",
    "\n",
    "    show_unique_features_from_full_solutions(df_outlier)\n",
    "\n",
    "    show_features_in_components(\n",
    "        solutions=outlier_features[f\"{deviation}\"],\n",
    "        features_to_show=get_unique_features(outlier_features[f\"{deviation}\"]),\n",
    "    )\n",
    "\n",
    "    display(Markdown(f\"## Regression on discovered outlier ({deviation}) features\"))\n",
    "    penalty = \"l2\"\n",
    "    metrics = solve_any_regression(\n",
    "        solutions=outlier_features[f\"{deviation}\"],\n",
    "        df=df,\n",
    "        response=y,\n",
    "        apply_scaling=\"standard\",\n",
    "        penalty=penalty,\n",
    "        verbose=False,  # if true, shows detailed results for each solution\n",
    "    )\n",
    "    show_regression_metrics(\n",
    "        metrics_df=metrics,\n",
    "        title=f\"Outlier ({deviation}) features - regression results on training data (penalty = {penalty})\",\n",
    "        use_markdown=True,\n",
    "    )\n",
    "\n",
    "    display(\n",
    "        Markdown(\n",
    "            f\"## Compare discovered outlier ({deviation}) features with ground truth\"\n",
    "        )\n",
    "    )\n",
    "    compare_true_and_found_features(\n",
    "        features_found=features_found,\n",
    "        true_support_features=true_support_features,\n",
    "        n_total_features=len(df.columns),\n",
    "    )\n",
    "\n",
    "    display(Markdown(\"------------------------------------------------------------\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbcf48c3",
   "metadata": {},
   "source": [
    "## Full solutions\n",
    "\n",
    "The 'full' solutions contain all features that are not \"negligible\", i.e. greater than a given manual threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc6f3a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_features = get_features_from_solutions(full_solutions)\n",
    "features_found = get_unique_features(full_features)\n",
    "\n",
    "show_solution_summary(\n",
    "    solution_data=full_solutions,\n",
    "    title=\"Full solutions found by the feature selector, ordered by importance\",\n",
    "    value_column=\"Feature\",\n",
    ")\n",
    "\n",
    "show_unique_features_from_full_solutions(full_solutions)\n",
    "\n",
    "show_features_in_components(\n",
    "    solutions=full_features,\n",
    "    features_to_show=features_found,\n",
    ")\n",
    "\n",
    "display(Markdown(\"## Regression on discovered full features\"))\n",
    "for penalty in [\"l2\", \"l1\"]:\n",
    "    metrics = solve_any_regression(\n",
    "        solutions=full_features,\n",
    "        df=df,\n",
    "        response=y,\n",
    "        apply_scaling=\"standard\",\n",
    "        penalty=penalty,\n",
    "        verbose=False,  # if true, shows detailed results for each solution\n",
    "    )\n",
    "    show_regression_metrics(\n",
    "        metrics_df=metrics,\n",
    "        title=f\"Full features - regression results on training data (penalty={penalty})\",\n",
    "        use_markdown=True,\n",
    "    )\n",
    "\n",
    "display(Markdown(\"## Compare discovered top features with ground truth\"))\n",
    "compare_true_and_found_features(\n",
    "    features_found=features_found,\n",
    "    true_support_features=true_support_features,\n",
    "    n_total_features=len(df.columns),\n",
    ")\n",
    "\n",
    "display(Markdown(\"------------------------------------------------------------\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c165119",
   "metadata": {},
   "source": [
    "## Top solutions\n",
    "\n",
    "The top solutions contain strictly the predefined number of features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "021988a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_features = get_features_from_solutions(top_solutions)\n",
    "features_found = get_unique_features(top_features)\n",
    "\n",
    "display(Markdown(f\"**Required sparsity:** {C.DESIRED_SPARSITY}\"))\n",
    "\n",
    "show_solution_summary(\n",
    "    solution_data=top_solutions,\n",
    "    title=f\"Top solutions with required sparsity = {C.DESIRED_SPARSITY}\",\n",
    "    value_column=\"Feature\",\n",
    ")\n",
    "\n",
    "show_unique_features_from_full_solutions(top_solutions)\n",
    "\n",
    "show_features_in_components(\n",
    "    solutions=top_features,\n",
    "    features_to_show=features_found,\n",
    ")\n",
    "\n",
    "show_correlation_matrix(df[sorted(features_found)], width=600, height=600)\n",
    "\n",
    "display(Markdown(\"## Regression on discovered top features\"))\n",
    "for penalty in [\"l2\", \"l1\"]:\n",
    "    metrics = solve_any_regression(\n",
    "        solutions=top_features,\n",
    "        df=df,\n",
    "        response=y,\n",
    "        apply_scaling=\"standard\",\n",
    "        penalty=penalty,\n",
    "        verbose=False,  # if true, shows detailed results for each solution\n",
    "    )\n",
    "    show_regression_metrics(\n",
    "        metrics_df=metrics,\n",
    "        title=f\"Top features - regression results on training data (penalty = {penalty})\",\n",
    "        use_markdown=True,\n",
    "    )\n",
    "\n",
    "display(Markdown(\"## Compare discovered top features with ground truth\"))\n",
    "compare_true_and_found_features(\n",
    "    features_found=features_found,\n",
    "    true_support_features=true_support_features,\n",
    "    n_total_features=len(df.columns),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59cc2466",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
