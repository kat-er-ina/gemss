{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a60e71fc",
   "metadata": {},
   "source": [
    "# GEMSS Demo\n",
    "\n",
    "This notebook demonstrates the GEMSS algorithm on artificially generated data.\n",
    "\n",
    "**Features:**\n",
    "- Modular prior (structured spike-and-slab by default)\n",
    "- Flexible mixture model\n",
    "- Variational inference with PyTorch\n",
    "- Performance diagnostics with Plotly\n",
    "- Reliability and tuning recommendations based on performance diagnostics\n",
    "\n",
    "> **Note:** Ensure that the `gemss` package and dependencies are installed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b535593",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install -q -e .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebb99998",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add parent directory to Python path to find our package\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "parent_dir = Path(os.path.dirname(os.getcwd()))\n",
    "if parent_dir not in sys.path:\n",
    "    sys.path.insert(0, str(parent_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6845e612",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from IPython.display import display, Markdown\n",
    "import pandas as pd\n",
    "import plotly.io as pio\n",
    "\n",
    "import gemss.config as C\n",
    "from gemss.data_handling.generate_artificial_dataset import (\n",
    "    generate_artificial_dataset,\n",
    ")\n",
    "from gemss.feature_selection.inference import BayesianFeatureSelector\n",
    "from gemss.diagnostics.visualizations import (\n",
    "    show_correlation_matrix,\n",
    "    show_features_in_components,\n",
    ")\n",
    "from gemss.diagnostics.performance_tests import run_performance_diagnostics\n",
    "from gemss.diagnostics.recommendations import display_recommendations\n",
    "from gemss.diagnostics.result_postprocessing import (\n",
    "    compare_true_and_found_features,\n",
    "    get_unique_features,\n",
    "    recover_solutions,\n",
    "    show_final_parameter_comparison,\n",
    "    show_algorithm_progress,\n",
    "    show_features_in_solutions,\n",
    ")\n",
    "from gemss.utils import show_solution_summary\n",
    "from gemss.diagnostics.simple_regressions import (\n",
    "    solve_with_logistic_regression,\n",
    "    solve_with_linear_regression,\n",
    "    show_regression_results_for_solutions,\n",
    ")\n",
    "from gemss.diagnostics.visualizations import show_final_alphas\n",
    "from gemss.diagnostics.outliers import (\n",
    "    get_outlier_summary_from_history,\n",
    "    show_outlier_summary,\n",
    "    show_outlier_features_by_component,\n",
    ")\n",
    "\n",
    "pio.renderers.default = \"notebook_connected\"  # Ensures plotly plots show in notebooks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d294cdd",
   "metadata": {},
   "source": [
    "# Generate artificial dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "104d75a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate dataset\n",
    "df, y, generating_solutions, parameters = generate_artificial_dataset(\n",
    "    n_samples=C.N_SAMPLES,\n",
    "    n_features=C.N_FEATURES,\n",
    "    n_solutions=C.N_GENERATING_SOLUTIONS,\n",
    "    sparsity=C.SPARSITY,\n",
    "    noise_data_std=C.NOISE_STD,\n",
    "    nan_ratio=C.NAN_RATIO,\n",
    "    binarize=C.BINARIZE,\n",
    "    binary_response_ratio=C.BINARY_RESPONSE_RATIO,\n",
    "    random_seed=C.DATASET_SEED,\n",
    "    save_to_csv=False,\n",
    "    print_data_overview=True,\n",
    "    show_feature_correlations=False,\n",
    ")\n",
    "\n",
    "support_indices = parameters[\"support_indices\"].sum()\n",
    "true_support_features = [f\"feature_{i}\" for i in set(support_indices)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a945c681",
   "metadata": {},
   "source": [
    "# Classical approach\n",
    "\n",
    "If there is an acceptable amount of missing values, solve the problem using logistic/linear regression with regularization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ec94b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show regression results only for the generating solutions and the full feature set\n",
    "generating_solutions_expanded = generating_solutions\n",
    "generating_solutions_expanded[\"original feature set\"] = df.columns.to_list()\n",
    "\n",
    "for penalty in [\"l1\", \"l2\"]:\n",
    "    show_regression_results_for_solutions(\n",
    "        solutions=generating_solutions_expanded,\n",
    "        df=df,\n",
    "        response=y,\n",
    "        penalty=penalty,\n",
    "        verbose=False,  # if true, shows detailed results for each solution\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccf3a053",
   "metadata": {},
   "source": [
    "# GEMSS: running a Bayesian feature selector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0abe75e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "selector = BayesianFeatureSelector(\n",
    "    n_features=C.N_FEATURES,\n",
    "    n_components=C.N_CANDIDATE_SOLUTIONS,\n",
    "    X=df.values,\n",
    "    y=y,\n",
    "    prior=C.PRIOR_TYPE,\n",
    "    sss_sparsity=C.PRIOR_SPARSITY,\n",
    "    sample_more_priors_coeff=C.SAMPLE_MORE_PRIORS_COEFF,\n",
    "    var_slab=C.VAR_SLAB,\n",
    "    var_spike=C.VAR_SPIKE,\n",
    "    weight_slab=C.WEIGHT_SLAB,\n",
    "    weight_spike=C.WEIGHT_SPIKE,\n",
    "    student_df=C.STUDENT_DF,\n",
    "    student_scale=C.STUDENT_SCALE,\n",
    "    lr=C.LEARNING_RATE,\n",
    "    batch_size=C.BATCH_SIZE,\n",
    "    n_iter=C.N_ITER,\n",
    ")\n",
    "\n",
    "history = selector.optimize(\n",
    "    regularize=C.IS_REGULARIZED,\n",
    "    lambda_jaccard=C.LAMBDA_JACCARD,\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73bfb0c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The most important function: show_algorithm_progress\n",
    "# visualizes the optimization process by displaying the evolution of key metrics over iterations\n",
    "# essential for understanding model behavior and spotting issues\n",
    "show_algorithm_progress(history)\n",
    "\n",
    "# Compare the relative weights of the candidate solutions\n",
    "show_final_alphas(\n",
    "    history,\n",
    "    show_bar_plot=False,\n",
    "    show_pie_chart=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "904a22b0",
   "metadata": {},
   "source": [
    "## Outlier Analysis\n",
    "\n",
    "The outlier analysis helps identify features with unusually high importances (either positive or negative mu values) in each component.\n",
    "\n",
    "Ideally, the detected outliers are identical to the final solutions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b6ed831",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show outlier features\n",
    "for outlier_threshold_coeff in [2.5, 3.0, 3.5]:\n",
    "    show_outlier_features_by_component(\n",
    "        history=history,\n",
    "        use_median=False,\n",
    "        outlier_threshold_coeff=outlier_threshold_coeff,\n",
    "        use_markdown=True,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aa123df",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbcf48c3",
   "metadata": {},
   "source": [
    "## Overview of full (long) solutions\n",
    "\n",
    "The 'long' solutions are the actual solutions (full sets of features) found by the algorithm. Their sparsity may not be as strong as desired."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5852ccb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "solutions, final_parameters, full_nonzero_solutions = recover_solutions(\n",
    "    search_history=history,\n",
    "    desired_sparsity=C.DESIRED_SPARSITY,\n",
    "    min_mu_threshold=C.MIN_MU_THRESHOLD,\n",
    "    verbose=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc6f3a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_solution_summary(\n",
    "    solution_data=full_nonzero_solutions,\n",
    "    title=\"Full solutions found by the feature selector, ordered by importance\",\n",
    "    value_column=\"Feature\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c165119",
   "metadata": {},
   "source": [
    "## Assessment of (short) solutions\n",
    "\n",
    "The short solutions are just the most important features from the long solutions. The number of features selected is defined by the desired sparsity parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "021988a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_features_in_solutions(\n",
    "    solutions=solutions,\n",
    "    history=history,\n",
    "    constants=C.as_dict(),\n",
    "    use_markdown=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bec03fba",
   "metadata": {},
   "source": [
    "## Overview of discovered features in the short solutions\n",
    "\n",
    "Comparison of the \"ground truth\" set of features that support the original solutions and the discovered set of features across all (short) candidate solutions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9987afc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_found = get_unique_features(solutions)\n",
    "\n",
    "compare_true_and_found_features(\n",
    "    features_found=features_found,\n",
    "    true_support_features=true_support_features,\n",
    "    n_total_features=len(df.columns),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed1a47af",
   "metadata": {},
   "source": [
    "## Mutual comparison of the short solutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28152532",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(pd.DataFrame.from_dict(solutions, orient=\"index\").T)\n",
    "\n",
    "features_to_show = list(set(true_support_features).union(set(features_found)))\n",
    "show_features_in_components(solutions, features_to_show=features_to_show)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21000d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_correlation_matrix(df[sorted(features_to_show)], width=600, height=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e225c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display(Markdown(\"### Mixture means vs. true means\"))\n",
    "# show_final_parameter_comparison(\n",
    "#     true_parameters=parameters,\n",
    "#     final_parameters=final_parameters,\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "573acc83",
   "metadata": {},
   "source": [
    "# Compute regression using features in short solutions\n",
    "\n",
    "See how the short candidate solutions perform when simple logistic/linear regression is applied."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f08252b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for penalty in [\"l1\", \"l2\"]:\n",
    "    show_regression_results_for_solutions(\n",
    "        solutions=solutions,\n",
    "        df=df,\n",
    "        response=y,\n",
    "        penalty=penalty,\n",
    "        verbose=False,  # if true, shows detailed results for each solution\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bedeafe9",
   "metadata": {},
   "source": [
    "# Performance diagnostics (work in progress)\n",
    "\n",
    "Let us assess the feature selector's progress history to evaluate the reliability of the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80c3fdd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "diagnostics = run_performance_diagnostics(\n",
    "    history,\n",
    "    desired_sparsity=C.as_dict()[\"DESIRED_SPARSITY\"],\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45e3d632",
   "metadata": {},
   "source": [
    "## Recommendations (work in progress)\n",
    "\n",
    "Based on the diagnostics, hyperparameter tuning might be recommended."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8efa58dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_recommendations(\n",
    "    diagnostics=diagnostics,\n",
    "    constants=C.as_dict(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9242d592",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
