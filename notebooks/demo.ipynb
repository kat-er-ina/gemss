{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayesian Sparse Feature Selection Demo\n",
    "\n",
    "This notebook demonstrates the Bayesian Gaussian Mixture Feature Selection algorithm on artificial data.\n",
    "\n",
    "**Features:**\n",
    "- Modular prior (spike-and-slab, easily replaceable)\n",
    "- Flexible mixture model\n",
    "- Variational inference with PyTorch\n",
    "- Interactive diagnostics with Plotly/Seaborn\n",
    "\n",
    "> **Note:** Ensure that the `feature_selection` package and dependencies are installed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b535593",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install -q -e .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebb99998",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add parent directory to Python path to find our package\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "parent_dir = Path(os.path.dirname(os.getcwd()))\n",
    "if parent_dir not in sys.path:\n",
    "    sys.path.insert(0, str(parent_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6845e612",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, List\n",
    "from IPython.display import display, Markdown\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import plotly.io as pio\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "import feature_selection.config as C\n",
    "from feature_selection.utils import (\n",
    "    solve_with_logistic_regression,\n",
    "    solve_with_linear_regression,\n",
    "    recover_solutions,\n",
    "    display_features_overview,\n",
    "    show_regression_results_for_solutions,\n",
    "    show_algorithm_progress,\n",
    ")\n",
    "from feature_selection.inference import BayesianFeatureSelector\n",
    "from feature_selection.visualizations import (\n",
    "    plot_elbo,\n",
    "    plot_mu,\n",
    "    plot_alpha,\n",
    "    show_correlation_matrix,\n",
    "    show_correlations_with_response,\n",
    "    show_label_histogram,\n",
    "    show_features_in_components,\n",
    "    compare_parameters,\n",
    ")\n",
    "from feature_selection.generate_artificial_dataset import (\n",
    "    generate_artificial_dataset,\n",
    ")\n",
    "\n",
    "pio.renderers.default = \"notebook_connected\"  # Ensures plotly plots show in notebooks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f1a3492",
   "metadata": {},
   "source": [
    "# Import parameters and settings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d294cdd",
   "metadata": {},
   "source": [
    "# Generate Artificial Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "104d75a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate dataset\n",
    "df, y, generating_solutions, parameters = generate_artificial_dataset(\n",
    "    n_samples=C.NSAMPLES,\n",
    "    n_features=C.NFEATURES,\n",
    "    n_solutions=C.NSOLUTIONS,\n",
    "    sparsity=C.SPARSITY,\n",
    "    noise_data_std=C.NOISE_STD,\n",
    "    binarize=C.BINARIZE,\n",
    "    binary_response_ratio=C.BINARY_RESPONSE_RATIO,\n",
    "    random_seed=C.RANDOM_SEED,\n",
    "    save_to_csv=False,\n",
    "    print_data_overview=True,\n",
    ")\n",
    "\n",
    "support_indices = parameters[\"support_indices\"].sum()\n",
    "true_support_features = [f\"feature_{i}\" for i in set(support_indices)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a945c681",
   "metadata": {},
   "source": [
    "# Classical approach\n",
    "Solve the classification problem using logistic regression with l1 penalty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "905f7422",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solve the full problem (all features) with l2 penalty\n",
    "#\n",
    "# if BINARIZE:\n",
    "#     solve_with_logistic_regression(X=df, y=y, penalty=\"l2\")\n",
    "# else:\n",
    "#     solve_with_linear_regression(X=df, y=y, penalty=\"l2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ce36c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solve the full problem (all features) with l1 penalty\n",
    "if C.BINARIZE:\n",
    "    solve_with_logistic_regression(X=df, y=y, penalty=\"l1\")\n",
    "else:\n",
    "    solve_with_linear_regression(X=df, y=y, penalty=\"l1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ec94b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show regression results only for the generating solutions\n",
    "show_regression_results_for_solutions(\n",
    "    solutions=generating_solutions,\n",
    "    df=df,\n",
    "    y=y,\n",
    "    penalty=\"l1\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c8eccae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solve for arbitrary combinations of features\n",
    "combinations = [\n",
    "    # [\"3\", \"17\", \"30\", \"39\"],\n",
    "]\n",
    "\n",
    "for combination in combinations:\n",
    "    display(Markdown(f\"## Regression model for component {combination}\"))\n",
    "    features = [f\"feature_{i}\" for i in combination]\n",
    "    display(Markdown(f\"- Support features: {features}\"))\n",
    "    if C.BINARIZE:\n",
    "        solve_with_logistic_regression(X=df[features], y=y, penalty=\"l1\")\n",
    "    else:\n",
    "        solve_with_linear_regression(X=df[features], y=y, penalty=\"l1\")\n",
    "    display(Markdown(\"------------------\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccf3a053",
   "metadata": {},
   "source": [
    "# Bayesian Feature Selector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0abe75e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "selector = BayesianFeatureSelector(\n",
    "    n_features=C.NFEATURES,\n",
    "    n_components=C.N_COMPONENTS,\n",
    "    X=df.values,\n",
    "    y=y,\n",
    "    prior=C.PRIOR_TYPE,\n",
    "    sss_sparsity=C.PRIOR_SPARSITY,\n",
    "    var_slab=C.VAR_SLAB,\n",
    "    var_spike=C.VAR_SPIKE,\n",
    "    weight_slab=C.WEIGHT_SLAB,\n",
    "    weight_spike=C.WEIGHT_SPIKE,\n",
    "    student_df=C.STUDENT_DF,\n",
    "    student_scale=C.STUDENT_SCALE,\n",
    "    lr=C.LEARNING_RATE,\n",
    "    batch_size=C.BATCH_SIZE,\n",
    "    n_iter=C.N_ITER,\n",
    ")\n",
    "\n",
    "history = selector.optimize(\n",
    "    regularize=C.IS_REGULARIZED,\n",
    "    lambda_jaccard=C.LAMBDA_JACCARD,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "show_algorithm_progress(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aa123df",
   "metadata": {},
   "source": [
    "## Solution quality assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "021988a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "solutions, final_parameters, full_nonzero_solutions = recover_solutions(\n",
    "    search_history=history,\n",
    "    desired_sparsity=C.DESIRED_SPARSITY,\n",
    "    min_mu_threshold=C.MIN_MU_THRESHOLD,\n",
    "    verbose=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bec03fba",
   "metadata": {},
   "source": [
    "## Overview of discovered features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9987afc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_found = set().union(\n",
    "    *solutions.values()\n",
    ")  # unique features occuring in any component\n",
    "\n",
    "\n",
    "display_features_overview(\n",
    "    features_found=features_found,\n",
    "    true_support_features=true_support_features,\n",
    "    n_total_features=len(df.columns),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed1a47af",
   "metadata": {},
   "source": [
    "## Comparison of the solutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28152532",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(pd.DataFrame.from_dict(solutions, orient=\"index\").T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21000d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_to_show = list(set(true_support_features).union(set(features_found)))\n",
    "show_features_in_components(solutions, features_to_show=features_to_show)\n",
    "\n",
    "show_correlation_matrix(df[sorted(features_to_show)], width=600, height=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a5be51b",
   "metadata": {},
   "source": [
    "## Mixture means vs. true means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e225c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show final mixture means and weights\n",
    "compare_parameters(parameters, final_parameters[\"final mu\"])\n",
    "\n",
    "display(Markdown(\"### Final mixture weights (alpha):\"))\n",
    "for i, alpha in enumerate(final_parameters[\"final alpha\"]):\n",
    "    display(Markdown(f\"- **Component {i}:** {alpha:.3f}\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f08252b3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
